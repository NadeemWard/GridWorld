{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is a quick demonstration of some of the functionalities of the gridworld package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 main classes within this package:\n",
    "- a GridWorld class that defines a grid\n",
    "- a Transition_Probs class that defines the transition probabilities of the grid\n",
    "- a Rewards class that defines the rewards associated with the Grid\n",
    "- a Agent class that defines an agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An instance of a grid can be defined by specifing the height and width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|1\t2\t3\t4\t|\n",
      "|5\t6\t7\t8\t|\n",
      "|9\t10\t11\t12\t|\n",
      "|13\t14\t15\t16\t|\n"
     ]
    }
   ],
   "source": [
    "from gridworld.Grid import GridWorld\n",
    "\n",
    "height = 4 \n",
    "width = 4\n",
    "\n",
    "grid = GridWorld(4,4)\n",
    "grid.print_grid() # simple printing function to visualize the grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we proceed to environment dynamics: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transitions probabilities are defined over a set of actions on a grid. An instance can be created as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gridworld.Transitions import Transitions_Probs\n",
    "\n",
    "# define the actions \n",
    "actions = [\"up\",\"down\",\"left\",\"right\"]\n",
    "\n",
    "tp = Transitions_Probs(grid,actions) # transitions are defined over a grid given a set of actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transitions are bascially a 3-D matrix defined as [states][actions][states] to be able to capture the usual notion of transitions in MDP; P(s' | s , a).\n",
    "\n",
    "You are therefore given the freedom to define any set of actions over this gridworld that can have any set of desired outcome. You will just have to be able to construct the appropriate 3-D matrix associated. \n",
    "\n",
    "For example, if I want to have an action \"jump\" that moves me 2 spaces in the grid. I will have to have a transtion matrix that represents this. Say I'm in state 1 and want to use action \"jump right\" and have the desired outcome always occur (i.e. no stochastisity envolved). Then, in the 3-D matrix I would set [1][\"jump right\"][3] = 1. Therefore given a probability of 1 to ending up in state 3 given that I jumped right at state 1. This would then have to be done for all (state,actions,state) elements in the matrix. \n",
    "\n",
    "In this way, arbitrary actions and transitions can be specified. To simply this for the user, there exists functions to directly create common transition assume the usual \"up\",\"down\",\"left\",\"right\" actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.create_common_transition(\"Deterministic\") # no stochastisity always move where the agent wants to go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.7\n",
    "tp.create_common_transition( (\"Bernoulli\", p) ) # Associate a probability of success of moving \n",
    "                                               # in the desired direction. w.p (1-p) agent stays where it is\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.create_common_transition( (\"Random\", p)) # Similar to \"Bernoulli\" except you move in a random other direction\n",
    "                                            # with probability (1-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "terminal_states = [16] \n",
    "tp.add_terminal_states(terminal_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to Transitions, rewards are also define as a 3-D matrix. This allows the user to make rather complex rewards functions if he/she wishes. They are defined on a grid for a given set of actions.\n",
    "\n",
    "Also similar to Transitions, there is a function for commonly used rewards call \"commom_reward\". Here, we assume the rewards to be fixed constants (not from a distribution although one could create a 3-D that does this) for a given state. The way of creating this can be as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gridworld.Rewards import Reward\n",
    "\n",
    "reward_env = Reward(grid, actions) # create the reward_env for this grid environment given the set of actions\n",
    "\n",
    "# If the rewards are constant for a state, this can be specified in a dictionary \n",
    "#{ state1:reward1 , state2:reward2 , ...} \n",
    "\n",
    "defined_reward = {1:1 , 4:10} # Here, at state 1 I have a reward of 1 and at state 4 I have a reward of 10.\n",
    "# now create the environment with the given rewards\n",
    "reward_env.common_reward(defined_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it must be a dictionary for the function to work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An agent must be defined on a grid with a given set of actions and a policy. \n",
    "\n",
    "The policy is just a 2-D matrix (state,actions). $\\pi$(a|s) = P(agent chooses action a | it is in state s). We can do this simply as follows using numpy matricies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# create the uniform policy \n",
    "policy = np.ones( (len(grid.states), len(actions)) ) * 0.25 \n",
    "policy # each entry (row s , column a ) = P( agent chooses action a| it is in state s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now create the agent.\n",
    "from gridworld.Agent import Agent\n",
    "\n",
    "start_state = 1 # define where the agent starts\n",
    "agent = Agent(grid, actions, policy, start_state = start_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent has some functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gridworld.Agent.Agent at 0x7f341585b4e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.agent_copy() # create a new reference with the same attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.get_state() #returns current state of the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['left'], dtype='<U5')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.next_action() #returns the next action the agent will take given the policy \n",
    "                    # if the policy is a distribution (non deterministic) than it returns a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 'up', 1.0, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.outcome() #returns one step on the agent in the environment as a tuple (s1, a1, r2, s2)\n",
    "                # not that the agent's current state changes since it performed that move. Don't forget to reset \n",
    "                # the agent when necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample_episodes runs an episode of the agent in the environment. An episode can end based on different user specification: \n",
    "- the flag \"terminal_state=state\" tells the episode to end then\n",
    "- the flag \"steps_per_episode = N\" specifies how many steps before the episode end automatically "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(1, 'down', 0.0, 5),\n",
       "  (5, 'up', 1.0, 1),\n",
       "  (1, 'down', 0.0, 5),\n",
       "  (5, 'right', 0.0, 6),\n",
       "  (6, 'left', 0.0, 5),\n",
       "  (5, 'right', 0.0, 6),\n",
       "  (6, 'left', 0.0, 5),\n",
       "  (5, 'up', 1.0, 1),\n",
       "  (1, 'down', 0.0, 2),\n",
       "  (2, 'left', 0.0, 6),\n",
       "  (6, 'left', 0.0, 5),\n",
       "  (5, 'up', 1.0, 1),\n",
       "  (1, 'up', 1.0, 1),\n",
       "  (1, 'up', 1.0, 1),\n",
       "  (1, 'right', 0.0, 2),\n",
       "  (2, 'down', 0.0, 6),\n",
       "  (6, 'right', 0.0, 7),\n",
       "  (7, 'down', 0.0, 11),\n",
       "  (11, 'left', 0.0, 10),\n",
       "  (10, 'left', 0.0, 9)],\n",
       " [(1, 'up', 1.0, 1),\n",
       "  (1, 'left', 1.0, 1),\n",
       "  (1, 'down', 0.0, 5),\n",
       "  (5, 'left', 0.0, 5),\n",
       "  (5, 'up', 1.0, 1),\n",
       "  (1, 'up', 1.0, 1),\n",
       "  (1, 'up', 1.0, 1),\n",
       "  (1, 'down', 0.0, 5),\n",
       "  (5, 'left', 0.0, 5),\n",
       "  (5, 'right', 0.0, 6),\n",
       "  (6, 'up', 0.0, 7),\n",
       "  (7, 'right', 0.0, 6),\n",
       "  (6, 'right', 0.0, 7),\n",
       "  (7, 'down', 0.0, 6),\n",
       "  (6, 'right', 0.0, 7),\n",
       "  (7, 'down', 0.0, 11),\n",
       "  (11, 'up', 0.0, 15),\n",
       "  (15, 'up', 0.0, 14),\n",
       "  (14, 'down', 0.0, 14),\n",
       "  (14, 'right', 0.0, 15)],\n",
       " [(1, 'up', 1.0, 1),\n",
       "  (1, 'down', 0.0, 5),\n",
       "  (5, 'right', 0.0, 6),\n",
       "  (6, 'left', 0.0, 5),\n",
       "  (5, 'right', 0.0, 6),\n",
       "  (6, 'left', 0.0, 5),\n",
       "  (5, 'up', 1.0, 1),\n",
       "  (1, 'up', 1.0, 1),\n",
       "  (1, 'left', 0.0, 2),\n",
       "  (2, 'down', 0.0, 6),\n",
       "  (6, 'left', 0.0, 5),\n",
       "  (5, 'up', 0.0, 6),\n",
       "  (6, 'down', 0.0, 10),\n",
       "  (10, 'down', 0.0, 14),\n",
       "  (14, 'left', 0.0, 13),\n",
       "  (13, 'down', 0.0, 13),\n",
       "  (13, 'down', 0.0, 13),\n",
       "  (13, 'right', 0.0, 14),\n",
       "  (14, 'right', 0.0, 15),\n",
       "  (15, 'down', 0.0, 15)],\n",
       " [(1, 'down', 0.0, 5),\n",
       "  (5, 'up', 1.0, 1),\n",
       "  (1, 'right', 0.0, 2),\n",
       "  (2, 'down', 0.0, 3),\n",
       "  (3, 'left', 0.0, 3),\n",
       "  (3, 'down', 0.0, 7),\n",
       "  (7, 'up', 0.0, 3),\n",
       "  (3, 'right', 10.0, 4),\n",
       "  (4, 'down', 0.0, 8),\n",
       "  (8, 'left', 0.0, 7),\n",
       "  (7, 'right', 0.0, 8),\n",
       "  (8, 'right', 0.0, 8),\n",
       "  (8, 'right', 0.0, 8),\n",
       "  (8, 'right', 0.0, 8),\n",
       "  (8, 'right', 0.0, 8),\n",
       "  (8, 'left', 0.0, 7),\n",
       "  (7, 'right', 0.0, 8),\n",
       "  (8, 'left', 0.0, 7),\n",
       "  (7, 'left', 0.0, 6),\n",
       "  (6, 'down', 0.0, 5)],\n",
       " [(1, 'left', 1.0, 1),\n",
       "  (1, 'right', 0.0, 5),\n",
       "  (5, 'right', 0.0, 6),\n",
       "  (6, 'up', 0.0, 5),\n",
       "  (5, 'down', 0.0, 9),\n",
       "  (9, 'right', 0.0, 5),\n",
       "  (5, 'up', 1.0, 1),\n",
       "  (1, 'up', 1.0, 1),\n",
       "  (1, 'left', 0.0, 2),\n",
       "  (2, 'down', 0.0, 6),\n",
       "  (6, 'left', 0.0, 5),\n",
       "  (5, 'right', 0.0, 6),\n",
       "  (6, 'right', 0.0, 7),\n",
       "  (7, 'right', 0.0, 8),\n",
       "  (8, 'left', 0.0, 7),\n",
       "  (7, 'down', 0.0, 11),\n",
       "  (11, 'left', 0.0, 10),\n",
       "  (10, 'up', 0.0, 9),\n",
       "  (9, 'right', 0.0, 10),\n",
       "  (10, 'right', 0.0, 14)],\n",
       " [(1, 'left', 1.0, 1),\n",
       "  (1, 'up', 1.0, 1),\n",
       "  (1, 'left', 1.0, 1),\n",
       "  (1, 'down', 1.0, 1),\n",
       "  (1, 'left', 1.0, 1),\n",
       "  (1, 'right', 1.0, 1),\n",
       "  (1, 'down', 0.0, 5),\n",
       "  (5, 'down', 1.0, 1),\n",
       "  (1, 'left', 1.0, 1),\n",
       "  (1, 'down', 1.0, 1),\n",
       "  (1, 'left', 1.0, 1),\n",
       "  (1, 'down', 0.0, 5),\n",
       "  (5, 'up', 1.0, 1),\n",
       "  (1, 'down', 1.0, 1),\n",
       "  (1, 'left', 0.0, 2),\n",
       "  (2, 'down', 0.0, 6),\n",
       "  (6, 'left', 0.0, 5),\n",
       "  (5, 'up', 1.0, 1),\n",
       "  (1, 'down', 0.0, 5),\n",
       "  (5, 'up', 1.0, 1)],\n",
       " [(1, 'left', 0.0, 5),\n",
       "  (5, 'down', 0.0, 9),\n",
       "  (9, 'up', 0.0, 5),\n",
       "  (5, 'right', 0.0, 6),\n",
       "  (6, 'up', 0.0, 2),\n",
       "  (2, 'left', 0.0, 3),\n",
       "  (3, 'down', 10.0, 4),\n",
       "  (4, 'down', 0.0, 8),\n",
       "  (8, 'up', 0.0, 8),\n",
       "  (8, 'down', 0.0, 12),\n",
       "  (12, 'up', 0.0, 11),\n",
       "  (11, 'up', 0.0, 7),\n",
       "  (7, 'right', 0.0, 8),\n",
       "  (8, 'left', 0.0, 7),\n",
       "  (7, 'down', 0.0, 8),\n",
       "  (8, 'down', 0.0, 12),\n",
       "  (12, 'right', 0.0, 12),\n",
       "  (12, 'left', 0.0, 8),\n",
       "  (8, 'right', 0.0, 8),\n",
       "  (8, 'left', 0.0, 8)],\n",
       " [(1, 'left', 1.0, 1),\n",
       "  (1, 'up', 1.0, 1),\n",
       "  (1, 'right', 0.0, 2),\n",
       "  (2, 'left', 1.0, 1),\n",
       "  (1, 'left', 1.0, 1),\n",
       "  (1, 'down', 1.0, 1),\n",
       "  (1, 'left', 1.0, 1),\n",
       "  (1, 'left', 0.0, 2),\n",
       "  (2, 'right', 0.0, 3),\n",
       "  (3, 'left', 10.0, 4),\n",
       "  (4, 'down', 0.0, 3),\n",
       "  (3, 'left', 0.0, 3),\n",
       "  (3, 'left', 0.0, 2),\n",
       "  (2, 'up', 0.0, 2),\n",
       "  (2, 'up', 0.0, 2),\n",
       "  (2, 'down', 0.0, 6),\n",
       "  (6, 'right', 0.0, 7),\n",
       "  (7, 'right', 0.0, 8),\n",
       "  (8, 'left', 0.0, 7),\n",
       "  (7, 'down', 0.0, 6)],\n",
       " [(1, 'right', 1.0, 1),\n",
       "  (1, 'up', 1.0, 1),\n",
       "  (1, 'down', 0.0, 5),\n",
       "  (5, 'down', 0.0, 9),\n",
       "  (9, 'left', 0.0, 9),\n",
       "  (9, 'up', 0.0, 5),\n",
       "  (5, 'right', 0.0, 6),\n",
       "  (6, 'up', 0.0, 2),\n",
       "  (2, 'down', 0.0, 3),\n",
       "  (3, 'up', 0.0, 3),\n",
       "  (3, 'down', 0.0, 7),\n",
       "  (7, 'right', 0.0, 8),\n",
       "  (8, 'down', 0.0, 12),\n",
       "  (12, 'left', 0.0, 11),\n",
       "  (11, 'right', 0.0, 12),\n",
       "  (12, 'up', 0.0, 8),\n",
       "  (8, 'down', 0.0, 12),\n",
       "  (12, 'right', 0.0, 8),\n",
       "  (8, 'down', 0.0, 12),\n",
       "  (12, 'right', 0.0, 12)],\n",
       " [(1, 'right', 0.0, 2),\n",
       "  (2, 'left', 1.0, 1),\n",
       "  (1, 'left', 0.0, 5),\n",
       "  (5, 'left', 1.0, 1),\n",
       "  (1, 'left', 1.0, 1),\n",
       "  (1, 'left', 0.0, 2),\n",
       "  (2, 'left', 1.0, 1),\n",
       "  (1, 'left', 1.0, 1),\n",
       "  (1, 'up', 1.0, 1),\n",
       "  (1, 'up', 1.0, 1),\n",
       "  (1, 'down', 0.0, 5),\n",
       "  (5, 'right', 0.0, 6),\n",
       "  (6, 'left', 0.0, 5),\n",
       "  (5, 'left', 0.0, 5),\n",
       "  (5, 'up', 1.0, 1),\n",
       "  (1, 'left', 0.0, 5),\n",
       "  (5, 'left', 0.0, 5),\n",
       "  (5, 'right', 0.0, 9),\n",
       "  (9, 'down', 0.0, 13),\n",
       "  (13, 'left', 0.0, 13)]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_episodes = 10\n",
    "\n",
    "agent.sample_episode(10, terminal_state = 16, steps_per_episode = 20) # returns as a list of list of episodes\n",
    "                                                                      # will start at \"start_state\" specified before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
